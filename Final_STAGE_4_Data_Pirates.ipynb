{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvM1W9ZjvEYO",
        "outputId": "691832ff-330d-43ff-a97b-e9c6003aaeec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hrzb8-td5D0P4GLks3QBtzkCUzpszzP3\n",
            "To: /content/TravelInsurancePrediction.csv\n",
            "100% 115k/115k [00:00<00:00, 87.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1Hrzb8-td5D0P4GLks3QBtzkCUzpszzP3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq1v-aJH8yE9",
        "outputId": "2cffc930-0cb6-4e5b-9f31-eb060d6fb76d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.42.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/547.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/547.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.1/547.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.65.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.1)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.42.0 slicer-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlccZemx1jix"
      },
      "source": [
        "# Import Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SYvmt0TEvMNm"
      },
      "outputs": [],
      "source": [
        "#Data manipulation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Data visualization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Warning\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
        "\n",
        "#Preparation\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZVMN88-vM8e",
        "outputId": "f65ccbca-2765-4311-9ee5-ea5c62bd8b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzAv8qwnvOo4"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4qPXRS0vWe7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('TravelInsurancePrediction.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['TravelInsurance'].value_counts()"
      ],
      "metadata": {
        "id": "SW5dz7OFgRJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDojAh2svFbC"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset = ['Age','Employment Type','GraduateOrNot','AnnualIncome','FamilyMembers','ChronicDiseases','FrequentFlyer','EverTravelledAbroad',\"TravelInsurance\"])\n",
        "df.shape\n",
        "\n",
        "df['Employment Type']=df['Employment Type'].map({'Private Sector/Self Employed':1,'Government Sector':0})\n",
        "df['GraduateOrNot']=df['GraduateOrNot'].map({'Yes':1,'No':0})\n",
        "df['FrequentFlyer']=df['FrequentFlyer'].map({'No':0,'Yes':1})\n",
        "df['EverTravelledAbroad']=df['EverTravelledAbroad'].map({'No':0,'Yes':1})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TwCAbYDvgIU"
      },
      "outputs": [],
      "source": [
        "ft = [ 'Age', 'Employment Type', 'GraduateOrNot', 'AnnualIncome','FamilyMembers', 'ChronicDiseases', 'FrequentFlyer', 'EverTravelledAbroad']\n",
        "x = df[ft]\n",
        "y = df.TravelInsurance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D8-qAcEwDr8"
      },
      "outputs": [],
      "source": [
        "train_x,test_x,train_y,test_y = train_test_split(x, y, test_size=0.2, random_state=42) #split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpGHbvqNwSuz"
      },
      "outputs": [],
      "source": [
        "print(\"train_x size : \",train_x.size)\n",
        "print(\"test_x size  : \",test_x.size)\n",
        "print(\"train_y size : \",train_y.size)\n",
        "print(\"test_y size  : \",test_y.size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x.shape"
      ],
      "metadata": {
        "id": "vrxLimvPrXBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_y.value_counts()"
      ],
      "metadata": {
        "id": "SIIZgZNPsCrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv5PAJLVwHZm"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s967eJ-YwJNC"
      },
      "outputs": [],
      "source": [
        "print(pd.Series(train_y).value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWoO8z300H0a"
      },
      "source": [
        "# Oversampling Data Split dengan SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP5f8kiawL0L"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "X_train_over, y_train_over = SMOTE().fit_resample(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64sN6sN1xtlq"
      },
      "outputs": [],
      "source": [
        "# Sebelum Oversampling\n",
        "print('Target sebelum oversampling:')\n",
        "print(pd.Series(train_y).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6-awYKwx5vr"
      },
      "outputs": [],
      "source": [
        "# Setelah Oversampling\n",
        "print('Target setelah oversampling:')\n",
        "print(pd.Series(y_train_over).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDDWAFOeyX59"
      },
      "outputs": [],
      "source": [
        "y_train_over"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_eq2A3Dycj3"
      },
      "outputs": [],
      "source": [
        "X_train_over.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPE96Hf2ylXH"
      },
      "source": [
        "# DATA MODELLING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj2Xml-n1ji7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from imblearn.under_sampling import NearMiss\n",
        "#from catboost import CatBoostClassifier\n",
        "\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, precision_recall_curve, PrecisionRecallDisplay\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "#from yellowbrick.classifier import DiscriminationThreshold\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLJ9T8pXw8ey"
      },
      "outputs": [],
      "source": [
        "#model evaluation classification test (default)\n",
        "def eval_classification(model):\n",
        "    y_pred = model.predict(test_x)\n",
        "    y_pred_train = model.predict(train_x)\n",
        "    y_pred_proba = model.predict_proba(test_x)\n",
        "    y_pred_proba_train = model.predict_proba(train_x)\n",
        "\n",
        "    print(\"Accuracy (Test Set): %.2f\" % accuracy_score(test_y, y_pred))\n",
        "    print(\"Accuracy (Train Set): %.2f\" % accuracy_score(train_y, y_pred_train))\n",
        "\n",
        "    print(\"Precision (Test Set): %.2f\" % precision_score(test_y, y_pred))\n",
        "    print(\"Precision (Train Set): %.2f\" % precision_score(train_y, y_pred_train))\n",
        "\n",
        "    print(\"Recall (Test Set): %.2f\" % recall_score(test_y, y_pred))\n",
        "    print(\"Recall (Train Set): %.2f\" % recall_score(train_y, y_pred_train))\n",
        "\n",
        "    print(\"F1-Score (Test Set): %.2f\" % f1_score(test_y, y_pred))\n",
        "    print(\"F1-Score (Train Set): %.2f\" % f1_score(train_y, y_pred_train))\n",
        "\n",
        "    print(\"roc_auc (test-proba): %.2f\" % roc_auc_score(test_y, y_pred_proba[:, 1]))\n",
        "    print(\"roc_auc (train-proba): %.2f\" % roc_auc_score(train_y, y_pred_proba_train[:, 1]))\n",
        "\n",
        "    score = cross_validate(model, x, y, cv=5, scoring='roc_auc', return_train_score=True)\n",
        "    print('roc_auc (crossval train): '+ str(score['train_score'].mean()))\n",
        "    print('roc_auc (crossval test): '+ str(score['test_score'].mean()))\n",
        "\n",
        "\n",
        "def cnf_test(model):# Membuat Confusion Matrix (Test)\n",
        "    y_pred = model.predict(test_x)\n",
        "    y_pred_train = model.predict(train_x)\n",
        "    y_pred_proba = model.predict_proba(test_x)\n",
        "    y_pred_proba_train = model.predict_proba(train_x)\n",
        "    cnf_matrix = confusion_matrix(test_y, y_pred)\n",
        "    print(classification_report(test_y, y_pred))\n",
        "    sns.heatmap(cnf_matrix,cmap='coolwarm_r',annot=True,linewidth=0.5,fmt='d')\n",
        "    plt.title('Confusion Matrix (Test)')\n",
        "    plt.xlabel('Prediksi')\n",
        "    plt.ylabel('Aktual')\n",
        "\n",
        "def cnf_train(model):# Membuat Confusion Matrix (Test)\n",
        "    y_pred = model.predict(test_x)\n",
        "    y_pred_train = model.predict(train_x)\n",
        "    y_pred_proba = model.predict_proba(test_x)\n",
        "    y_pred_proba_train = model.predict_proba(train_x)\n",
        "    cnf_matrix = confusion_matrix(train_y, y_pred_train)\n",
        "    print(classification_report(train_y, y_pred_train))\n",
        "    sns.heatmap(cnf_matrix,cmap='coolwarm_r',annot=True,linewidth=0.5,fmt='d')\n",
        "    plt.title('Confusion Matrix (Train)')\n",
        "    plt.xlabel('Prediksi')\n",
        "    plt.ylabel('Aktual')\n",
        "\n",
        "def show_feature_importance(model):\n",
        "    feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
        "    ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.xlabel('score')\n",
        "    plt.ylabel('feature')\n",
        "    plt.title('feature importance score')\n",
        "\n",
        "def show_best_hyperparameter(model):\n",
        "    print(model.best_estimator_.get_params())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q1AfoL41LcX"
      },
      "source": [
        "# ML Supervised Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Declaring Functions\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "def eval_classification1(model):\n",
        "    y_pred = model.predict(test_x)\n",
        "    y_pred_train = model.predict(train_x)\n",
        "    y_pred_proba = model.predict_proba(test_x)\n",
        "    y_pred_proba_train = model.predict_proba(train_x)\n",
        "\n",
        "\n",
        "    acc_test = accuracy_score(test_y, y_pred)\n",
        "    precision_test = precision_score(test_y, y_pred)\n",
        "    recall_test = recall_score(test_y, y_pred)\n",
        "    f1_test = f1_score(test_y, y_pred)\n",
        "    roc_auc_train = roc_auc_score(train_y, y_pred_proba_train[:, 1])\n",
        "    roc_auc_test = roc_auc_score(test_y, y_pred_proba[:, 1])\n",
        "\n",
        "#     print(\"Accuracy (Test Set): %.2f\" % accuracy_score(y_test, y_pred))\n",
        "#     print(\"Precision (Test Set): %.2f\" % precision_score(y_test, y_pred))\n",
        "#     print(\"Recall (Test Set): %.2f\" % recall_score(y_test, y_pred))\n",
        "#     print(\"F1-Score (Test Set): %.2f\" % f1_score(y_test, y_pred))\n",
        "\n",
        "#     print(\"roc_auc (train-proba): %.2f\" % roc_auc_score(y_train, y_pred_proba_train[:, 1]))\n",
        "#     print(\"roc_auc (test-proba): %.2f\" % roc_auc_score(y_test, y_pred_proba[:, 1]))\n",
        "\n",
        "    score = cross_validate(model, x, y, cv=5, scoring='roc_auc', return_train_score=True)\n",
        "    roc_auc_crossval_train = round(score['train_score'].mean(), 4)\n",
        "    roc_auc_crossval_test = round(score['test_score'].mean(), 4)\n",
        "    # print('roc_auc (crossval train): '+ str(round(score['train_score'].mean(), 4)))\n",
        "    # print('roc_auc (crossval test): '+ str(round(score['test_score'].mean(), 4)))\n",
        "\n",
        "    eval_result = {\n",
        "        'Test Accuracy': acc_test,\n",
        "        'Test Precision': precision_test,\n",
        "        'Test Recall': recall_test,\n",
        "        'Test F1': f1_test,\n",
        "        'Train ROC AUC': roc_auc_train,\n",
        "        'Test ROC AUC': roc_auc_test,\n",
        "        'Crossval Train ROC AUC': roc_auc_crossval_train,\n",
        "        'Crossval Test ROC AUC': roc_auc_crossval_test\n",
        "    }\n",
        "    return eval_result\n",
        "\n",
        "def show_feature_importance1(model):\n",
        "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "    ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.xlabel('score')\n",
        "    plt.ylabel('feature')\n",
        "    plt.title('feature importance score')\n",
        "\n",
        "def show_best_hyperparameter1(model):\n",
        "    print(model.best_estimator_.get_params())"
      ],
      "metadata": {
        "id": "EliHSuDqL_ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all classifier\n",
        "from sklearn.linear_model import LogisticRegression # import Logistic Regression dari sklearn\n",
        "#from sklearn.neighbors import KNeighborsClassifier # import kNN dari sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier # import Decision Tree dari sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier # import Random Forest dari sklearn\n",
        "from sklearn.ensemble import AdaBoostClassifier # import AdaBoost dari sklearn\n",
        "from xgboost import XGBClassifier #import XGBoost darti xgboost\n",
        "\n",
        "#Evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score,precision_score,recall_score,f1_score,log_loss\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "Aav7DtqjLFqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling for Selected Algorithms\n",
        "\n",
        "# Selected Models\n",
        "models1 = ['Logistic Regression', 'Decision Tree', 'AdaBoost Classifier', 'XGB Classifier', 'Random Forest Classifier']\n",
        "algorithms1 = [LogisticRegression, DecisionTreeClassifier, AdaBoostClassifier, XGBClassifier, RandomForestClassifier]\n",
        "\n",
        "# List of results:\n",
        "acc_test_ni = []\n",
        "precision_test_ni = []\n",
        "recall_test_ni = []\n",
        "f1_test_ni = []\n",
        "roc_auc_train_ni = []\n",
        "roc_auc_test_ni = []\n",
        "roc_auc_crossval_train_ni = []\n",
        "roc_auc_crossval_test_ni = []"
      ],
      "metadata": {
        "id": "wM2n10T1LUJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating All Models Using Unhandled CLass Imbalance Data\n",
        "i = 0\n",
        "random_seed = [DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifier]\n",
        "\n",
        "for model_type in algorithms1:\n",
        "    # Fitting and using the algorithms\n",
        "    if model_type in random_seed:\n",
        "        model = model_type(random_state=42)\n",
        "    model = model_type(random_state=42)\n",
        "    model.fit(train_x, train_y)\n",
        "    print(models1[i])\n",
        "    result = eval_classification1(model)\n",
        "\n",
        "    # Adding the results to the list\n",
        "    acc_test_ni.append(result['Test Accuracy'])\n",
        "    precision_test_ni.append(result['Test Precision'])\n",
        "    recall_test_ni.append(result['Test Recall'])\n",
        "    f1_test_ni.append(result['Test F1'])\n",
        "    roc_auc_train_ni.append(result['Train ROC AUC'])\n",
        "    roc_auc_test_ni.append(result['Test ROC AUC'])\n",
        "    roc_auc_crossval_train_ni.append(result['Crossval Train ROC AUC'])\n",
        "    roc_auc_crossval_test_ni.append(result['Crossval Test ROC AUC'])\n",
        "\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "oQ1YY-_iLaSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame(list(zip(models1, acc_test_ni, precision_test_ni, recall_test_ni, f1_test_ni, roc_auc_train_ni, roc_auc_test_ni, roc_auc_crossval_train_ni, roc_auc_crossval_test_ni)), columns=['Algorithms', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Train ROC AUC', 'Test ROC AUC', 'Crossval Train ROC AUC', 'Crossval Test ROC AUC'])"
      ],
      "metadata": {
        "id": "j4scSiPFNHPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Basic Algorithm Result"
      ],
      "metadata": {
        "id": "gXKv15zBNyae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "tzLkqUSKNPc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjglxA6x2Tkv"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNTdRxY1w0QU"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(random_state = 42)#, class_weight='balanced')\n",
        "logreg.fit(train_x, train_y)\n",
        "eval_classification(logreg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(logreg)"
      ],
      "metadata": {
        "id": "cw7ismOkc6g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(logreg)"
      ],
      "metadata": {
        "id": "Lby1kEZGg77U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp92MUui2QIy"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIy1zORvws82"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(train_x, train_y)\n",
        "eval_classification(dt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(dt)"
      ],
      "metadata": {
        "id": "n3a6UjGjdgBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(dt)"
      ],
      "metadata": {
        "id": "YrcwilJfiz7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c16gReKl2X9s"
      },
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsGv_qS6yxY_"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "ada.fit(train_x, train_y)\n",
        "eval_classification(ada)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(ada)"
      ],
      "metadata": {
        "id": "-_r7wgOoi3Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(ada)"
      ],
      "metadata": {
        "id": "PY3J0WuLi36X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iEiBWdf2cxh"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq3bW6DezFv2"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xg = XGBClassifier(random_state=42)\n",
        "xg.fit(train_x, train_y)\n",
        "eval_classification(xg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(xg)"
      ],
      "metadata": {
        "id": "M91JWDcBi9FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(xg)"
      ],
      "metadata": {
        "id": "8nBfsxd-k9oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj-Yugww2jS7"
      },
      "source": [
        "## Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk8PHoT5_lbF"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(train_x, train_y)\n",
        "eval_classification(rf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(rf)"
      ],
      "metadata": {
        "id": "zrIeLUmNi959"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(rf)"
      ],
      "metadata": {
        "id": "r_2tBviBk5NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUd8zf7411xZ"
      },
      "source": [
        "# Model Using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling for Selected Algorithms\n",
        "\n",
        "# Selected Models\n",
        "models2 = ['Logistic Regression', 'Decision Tree', 'AdaBoost Classifier', 'XGB Classifier', 'Random Forest Classifier']\n",
        "algorithms2 = [LogisticRegression, DecisionTreeClassifier, AdaBoostClassifier, XGBClassifier, RandomForestClassifier]\n",
        "\n",
        "# List of results:\n",
        "acc_test_ni = []\n",
        "precision_test_ni = []\n",
        "recall_test_ni = []\n",
        "f1_test_ni = []\n",
        "roc_auc_train_ni = []\n",
        "roc_auc_test_ni = []\n",
        "roc_auc_crossval_train_ni = []\n",
        "roc_auc_crossval_test_ni = []"
      ],
      "metadata": {
        "id": "KkEM_DHjSKEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating All Models Using SMOTE\n",
        "i = 0\n",
        "random_seed = [DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifier]\n",
        "\n",
        "for model_type in algorithms1:\n",
        "    # Fitting and using the algorithms\n",
        "    if model_type in random_seed:\n",
        "        model = model_type(random_state=42)\n",
        "    model = model_type(random_state=42)\n",
        "    model.fit(X_train_over, y_train_over)\n",
        "    print(models2[i])\n",
        "    result = eval_classification1(model)\n",
        "\n",
        "    # Adding the results to the list\n",
        "    acc_test_ni.append(result['Test Accuracy'])\n",
        "    precision_test_ni.append(result['Test Precision'])\n",
        "    recall_test_ni.append(result['Test Recall'])\n",
        "    f1_test_ni.append(result['Test F1'])\n",
        "    roc_auc_train_ni.append(result['Train ROC AUC'])\n",
        "    roc_auc_test_ni.append(result['Test ROC AUC'])\n",
        "    roc_auc_crossval_train_ni.append(result['Crossval Train ROC AUC'])\n",
        "    roc_auc_crossval_test_ni.append(result['Crossval Test ROC AUC'])\n",
        "\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "552RyqY4S-O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df1 = pd.DataFrame(list(zip(models2, acc_test_ni, precision_test_ni, recall_test_ni, f1_test_ni, roc_auc_train_ni, roc_auc_test_ni, roc_auc_crossval_train_ni, roc_auc_crossval_test_ni)), columns=['Algorithms', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Train ROC AUC', 'Test ROC AUC', 'Crossval Train ROC AUC', 'Crossval Test ROC AUC'])"
      ],
      "metadata": {
        "id": "KD3gFR_4TOVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All SMOTE Based Algorithm"
      ],
      "metadata": {
        "id": "9CYSfwtsSLnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df1"
      ],
      "metadata": {
        "id": "UDWm5w_ATe64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h9UiCpV18L0"
      },
      "source": [
        "## Logistic Regression Using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3z9OR-I2vEU"
      },
      "outputs": [],
      "source": [
        "lrs = LogisticRegression(random_state = 42)#, class_weight='balanced')\n",
        "lrs.fit(X_train_over, y_train_over)\n",
        "eval_classification(lrs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(lrs)"
      ],
      "metadata": {
        "id": "3G5jtTYli_B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(lrs)"
      ],
      "metadata": {
        "id": "23yWc7Mskzz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8to1nG8Y1_tb"
      },
      "source": [
        "## Decision Tree Using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVSLHg7F2ywA"
      },
      "outputs": [],
      "source": [
        "dts = DecisionTreeClassifier(random_state=42)\n",
        "dts.fit(X_train_over, y_train_over)\n",
        "eval_classification(dts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(dts)"
      ],
      "metadata": {
        "id": "cor-V-Qhi_pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(dts)"
      ],
      "metadata": {
        "id": "kQzURHC7ku7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZdQuAED2FRi"
      },
      "source": [
        "## AdaBoost Using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HMtLAP-23YK"
      },
      "outputs": [],
      "source": [
        "adas = AdaBoostClassifier(random_state=42)\n",
        "adas.fit(X_train_over, y_train_over)\n",
        "eval_classification(adas)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(adas)"
      ],
      "metadata": {
        "id": "CNdrTW61jAGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(adas)"
      ],
      "metadata": {
        "id": "va8NMJR7j8Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpT4qb-N2EbO"
      },
      "source": [
        "## XGBoost Using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L442hcN27fX"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgs = XGBClassifier(random_state=42)\n",
        "xgs.fit(X_train_over, y_train_over)\n",
        "eval_classification(xgs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(xgs)"
      ],
      "metadata": {
        "id": "27tfSKCejAoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnf_test(xgs)"
      ],
      "metadata": {
        "id": "nATsg_w2j26O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGUDcT0E2D-G"
      },
      "source": [
        "## Random Forest Using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6o3_kmX2-R9"
      },
      "outputs": [],
      "source": [
        "rfs = RandomForestClassifier(random_state=42)\n",
        "rfs.fit(X_train_over, y_train_over)\n",
        "eval_classification(rfs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(rfs)"
      ],
      "metadata": {
        "id": "8Yd5hRwtjBLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(rfs)"
      ],
      "metadata": {
        "id": "j-8Qq5lXjzMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew8DA6Hx1jjA"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, learning_curve\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Menjadikan ke dalam bentuk dictionary\n",
        "hyperparameters = {\n",
        "                    'max_depth' : [int(x) for x in np.linspace(10, 110, num = 11)],\n",
        "                    'min_child_weight' : [int(x) for x in np.linspace(1, 20, num = 11)],\n",
        "                    'gamma' : [float(x) for x in np.linspace(0, 1, num = 11)],\n",
        "                    'tree_method' : ['auto', 'exact', 'approx', 'hist'],\n",
        "\n",
        "                    'colsample_bytree' : [float(x) for x in np.linspace(0, 1, num = 11)],\n",
        "                    'eta' : [float(x) for x in np.linspace(0, 1, num = 100)],\n",
        "\n",
        "                    'lambda' : [float(x) for x in np.linspace(0, 1, num = 11)],\n",
        "                    'alpha' : [float(x) for x in np.linspace(0, 1, num = 11)]\n",
        "                    }\n",
        "\n",
        "# Init\n",
        "from xgboost import XGBClassifier\n",
        "xgsa = XGBClassifier(random_state=42)\n",
        "xg_tuned = RandomizedSearchCV(xgsa, hyperparameters, cv=5, random_state=42, scoring='f1')\n",
        "xg_tuned.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Predict & Evaluation\n",
        "eval_classification(xg_tuned)"
      ],
      "metadata": {
        "id": "DhTBzZw-gmWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(xg_tuned)"
      ],
      "metadata": {
        "id": "BV3svhJPdvS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(xg_tuned)"
      ],
      "metadata": {
        "id": "oWMjhywUjS8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat Learning Curve\n",
        "train_sizes, train_scores, validation_scores = learning_curve(xg_tuned.best_estimator_, X_train_over, y_train_over, cv=5)\n",
        "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='training score')\n",
        "plt.plot(train_sizes, np.mean(validation_scores, axis=1), label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# Menyimpan hasil gambar\n",
        "plt.savefig('learning_curve.png')"
      ],
      "metadata": {
        "id": "NSTpzIrqnhFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wi8T8ST1jjC"
      },
      "source": [
        "## XGBoost+SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPCpQxeg1jjC"
      },
      "outputs": [],
      "source": [
        "#show_best_hyperparameter(xgs)\n",
        "xgs_param_grid = {'n_estimators': np.linspace(100, 1000, 10, dtype=int),\n",
        "                  'learning_rate': np.arange(0.05, 1, 0.05),\n",
        "                  'max_depth': np.arange(3, 11, 1, dtype=int),\n",
        "                  'min_child_weight': np.arange(1, 8, 1, dtype=int),\n",
        "                  'tree_method' : ['auto', 'exact', 'approx', 'hist'],\n",
        "                  'gamma' : np.arange(0,10,0.5),\n",
        "                  #'lambda' : [float(x) for x in np.linspace(0, 1, num = 11)],\n",
        "                  'alpha' : [float(x) for x in np.linspace(0, 1, num = 11)],\n",
        "                  'colsample_bytree' : [float(x) for x in np.linspace(0, 1, num = 11)]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE453OJ21jjC"
      },
      "outputs": [],
      "source": [
        "xgs_rs = RandomizedSearchCV(xgs, xgs_param_grid, scoring='f1', cv=5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaxpi8p_1jjC"
      },
      "outputs": [],
      "source": [
        "xgs_rs.fit(X_train_over, y_train_over)\n",
        "\n",
        "print(f'Best parameters: {xgs_rs.best_params_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8AI497J1jjC"
      },
      "outputs": [],
      "source": [
        "xgs2 = XGBClassifier(random_state=42,\n",
        "                   tree_method= 'approx',\n",
        "                   n_estimators= 100,\n",
        "                   min_child_weight= 7,\n",
        "                   max_depth= 4,\n",
        "                   learning_rate= 0.8,\n",
        "                   #lambda= 0.30000000000000004,\n",
        "                   gamma= 7,\n",
        "                   colsample_bytree= 1,\n",
        "                   alpha= 0.9)\n",
        "\n",
        "xgs2.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Predict & Evaluation\n",
        "eval_classification(xgs2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_train(xgs2)"
      ],
      "metadata": {
        "id": "ZGMBWTsvjHgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_test(xgs2)"
      ],
      "metadata": {
        "id": "aQxXD_tEjJ9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB4rbrkI2DVm"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxINysmznjw8"
      },
      "outputs": [],
      "source": [
        "show_feature_importance(xg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dMPCv8nsRL-"
      },
      "source": [
        "5 Feature importance tertinggi adalah AnnualIncome, Family Members, Age, Ever Travelled Abroad, Chronic Diseases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgNNdqHnoaVY"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "explainer = shap.TreeExplainer(rf)\n",
        "shap_values = explainer.shap_values(test_x)\n",
        "shap.summary_plot(shap_values[1], test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV65b5ucsqF_"
      },
      "source": [
        "# Business Insight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ptZjLB7ss4f"
      },
      "source": [
        "Dari hasil analisa, perusahaan bisa fokus pada pelanggan yang memiliki karakteristik gabungan dari 5 feature importance tertinggi (Age, annual income, ever travelled abroad, Family members, Chronic diseases) agar bisa menarik pelanggan baru yang tepat sasaran.\n",
        "\n",
        "Dalam hal prospecting, perusahaan bisa memfokuskan penjualan ke calon klien yang sudah berkeluarga serta cenderung memiliki penyakit kronis yang sesuai dengan paket perlindungan asuransi dan pernah berpergian misalnya dengan memberikan promo terkait tiket perjalanan yang lebih murah apabila calon klien membeli paket asuransi travel. Hal tersebut dapat menarik minat pelanggan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNB0AR3fgzZW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}